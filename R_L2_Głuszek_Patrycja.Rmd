---
title: "ADPS 25Z --- Laboratorium 2 (rozwiązania)"
author: "Patrycja Głuszek"
output:
  pdf_document:
    latex_engine: xelatex
  html_notebook: default
  html_document: default
---

```{r, echo=FALSE}
pdf.options(encoding='ISOLatin2')
```

***

# Zadanie 1 (1 pkt)

## Treść zadania

Rozkład Poissona jest często używany do modelowania ruchu ulicznego (o małym natężeniu). Plik skrety.txt zawiera liczby pojazdów skręcających na pewnym skrzyżowaniu w prawo w przeciągu trzystu 3-minutowych przedziałów czasu (dane zostały zebrane o różnych porach dnia).

* Wczytaj dane za pomocą komendy scan('skrety.txt').

* Dopasuj do danych rozkład Poissona, tj. wyestymuj parametr $\lambda$ rozkładu Poissona, zapisz jego wartość w sprawozdaniu.

* Sprawdź i opisz zgodność rozkładu o wyestymowanym parametrze $\lambda$ z zarejestrowanymi danymi porównując graficznie empiryczną i teoretyczną funkcję prawdopodobieństwa. Użyj funkcji table() i\ dpois() analogicznie jak w przykładzie 4 laboratorium 1.

* Metodą bootstrapu nieparametrycznego oszacuj odchylenie standardowe estymatora parametru $\lambda$, zapisz jego wartość w sprawozdaniu.

## Rozwiązanie

tu umieść swoje rozwiązanie

```{r}
skrety <- scan("skrety.txt")

# Estymacja parametru lambda (MLE = średnia)
lambda_hat <- mean(skrety)

# Empiryczna pmf
tab <- table(skrety)
emp_pmf <- as.numeric(tab) / length(skrety)
x_vals <- as.integer(names(tab))

# Teoretyczna pmf Poissona
theo_pmf <- dpois(x_vals, lambda_hat)

# Wykres porównawczy (empiryczne vs teoretyczne)
barplot(rbind(emp_pmf, theo_pmf), beside=TRUE,
        col=c("pink","purple"), names.arg=x_vals,
        legend.text=c("empiryczne","teoretyczne"),
        main=expression(paste("Porównanie pmf: ", hat(lambda), " = ", round(lambda_hat,3))),
        xlab="Liczba pojazdów", ylab="Prawdopodobieństwo",
        ylim=c(0, max(emp_pmf,theo_pmf)*1.2))
grid()

# Bootstrap nieparametryczny dla odchylenia standardowego estymatora lambda
set.seed(123)
K <- 10000
boot_lambda <- replicate(K, mean(sample(skrety, length(skrety), replace=TRUE)))
sd_lambda <- sd(boot_lambda)

# 95% przedział ufności dla lambda (percentylowy bootstrap)
lambda_ci_boot <- quantile(boot_lambda, c(0.025, 0.975))
```

Wyestymowany parametr $\lambda$ rozkładu Poissona wynosi `r round(lambda_hat,4)`.

Odchylenie standardowe estymatora parametru $\lambda$ wynosi `r round(sd_lambda,4)`.


***

# Zadanie 2 (1 pkt)

## Treść zadania

* Dla wybranej jednej spółki notowanej na GPW oblicz wartości procentowych zmian najwyższych cen w\ dniu (Najwyzszy) w ciągu ostatniego roku i wykreśl ich histogram.

* Wyestymuj wartość średnią oraz wariancję procentowych zmian najwyższych cen dla wybranej spółki, zapisz te wartości w sprawozdaniu.

* Na podstawie histogramu i wykresu funkcji gęstości prawdopodobieństwa wyznaczonej dla wyestymowanych parametrów (wartość średnia i wariancja) zweryfikuj zgrubnie, czy możemy przyjąć, że procentowe zmiany najwyższych cen w dniu mają rozkład normalny.

* Zakładając, że zmiany najwyższych cen w dniu mają rozkład normalny wyznacz 90%, 95% i 99% przedziały ufności dla wartości średniej i wariancji procentowych zmian najwyższych cen w dniu dla wybranej spółki. Porównaj wyniki uzyskane dla różnych przedziałów ufności.

## Rozwiązanie

tu umieść swoje rozwiązanie

```{r}
library(quantmod)
symbol <- "PKN.WA"
getSymbols(symbol, from = Sys.Date() - 365, to = Sys.Date(), auto.assign = TRUE)
dane <- get(symbol)

# Procentowe zmiany (Najwyzszy) dzień do dnia, w %
h <- Hi(dane)
perc_change <- 100 * (h / lag(h) - 1)
perc_change <- na.omit(as.numeric(perc_change))  

# Histogram zmian
hist(perc_change, breaks = 20, main = 'Histogram % zmian najwyższych cen',
     xlab = '% zmiana', col = 'lightblue')

# Estymaty średniej i wariancji
mean_change <- mean(perc_change)
var_change <- var(perc_change)

# Histogram + dopasowana gęstość normalna
hist(perc_change, breaks = 20, probability = TRUE, col = 'lightblue',
     main = 'Zmiany % High: histogram + gęstość normalna')
curve(dnorm(x, mean_change, sqrt(var_change)), add = TRUE, col = 'darkblue', lwd = 2)

# Przedziały ufności
conf_levels <- c(0.90, 0.95, 0.99)
n <- length(perc_change)
S <- sd(perc_change)
x_mean <- mean_change

ci_results <- lapply(conf_levels, function(conf_lev) {
  w <- S * qt((1 + conf_lev) / 2, n - 1) / sqrt(n)
  mean_ci <- c(x_mean - w, x_mean + w)
  a <- (1 - conf_lev) / 2
  var_ci <- c((n - 1) * S^2 / qchisq(1 - a, n - 1),
              (n - 1) * S^2 / qchisq(a, n - 1))
  list(level = conf_lev, mean_ci = mean_ci, var_ci = var_ci)
})
```

Średnia procentowych zmian najwyższych cen wynosi `r round(mean_change,4)`. 

Wariancja procentowych zmian najwyższych cen wynosi `r round(var_change,4)`.


Na podstawie histogramu i dopasowanej gęstości normalnej możemy zgrubnie ocenić, 
że rozkład procentowych zmian najwyższych cen jest **zbliżony do normalnego**, 
choć mogą występować odchylenia w ogonach.

Zakładając normalność rozkładu, przedziały ufności dla średniej i wariancji wynoszą:
- 90%: średnia = `r paste(round(ci_results[[1]]$mean_ci,4), collapse=", ")`, wariancja = `r paste(round(ci_results[[1]]$var_ci,4), collapse=", ")`  
- 95%: średnia = `r paste(round(ci_results[[2]]$mean_ci,4), collapse=", ")`, wariancja = `r paste(round(ci_results[[2]]$var_ci,4), collapse=", ")`  
- 99%: średnia = `r paste(round(ci_results[[3]]$mean_ci,4), collapse=", ")`, wariancja = `r paste(round(ci_results[[3]]$var_ci,4), collapse=", ")`

Porównując wyniki: przedziały 99% są najszersze, 90% najwęższe. 
Im wyższy poziom ufności, tym większa niepewność i szerszy zakres wartości.

***

# Zadanie 3 (1,5 pkt.)

## Treść zadania

Rzucona pinezka upada ostrzem do dołu lub do góry. Doświadczenie to można opisać rozkładem Bernoulliego z parametrem $p$ będącym prawdopodobieństwem tego, że pinezka upadnie ostrzem do góry. 

Rozkład parametru $p$ można opisać rozkładem beta o parametrach $\alpha$ i $\beta$. Wartość średnia i wariancja w\ rozkładzie beta zależą od parametrów rozkładu w następujący sposób:
$$ \mathbb{E}X = \frac{\alpha}{\alpha + \beta}, \qquad \mathbb{V}X = \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}, \qquad dominanta = \frac{\alpha - 1}{\alpha + \beta - 2}.$$

* Na podstawie przypuszczanej (a priori) wartości oczekiwanej parametru $p$ zaproponuj wartości parametrów $\alpha$ i $\beta$ rozkładu a priori parametru $p$. Narysuj rozkład a priori parametru $p$ (wykorzystaj funkcję dbeta()).

* Rzuć pinezką 20 razy i zanotuj wyniki kolejnych rzutów (1 - pinezka upada ostrzem do góry, 0 - pinezka upada ostrzem do dołu). Wyznacz i narysuj rozkład a posteriori parametru $p$ oraz oblicz wartość bayesowskiego estymatora $\hat{p}$. W\ rozważanym przypadku rozkład aposteriori parametru $p$ jest również rozkładem beta o parametrach:
$$ \alpha_{\textrm{post}} = \alpha_{\textrm{prior}} + \sum_{i=1}^n x_i, \qquad \beta_{\textrm{post}} = \beta_{\textrm{prior}} + n - \sum_{i=1}^n x_i,\qquad x_i\in\{0,1\}.$$

* Rzuć pinezką jeszcze 20 razy i zanotuj wyniki. Wyznacz i narysuj rozkład a posteriori oparty na wszystkich 40 rzutach oraz oblicz wartość bayesowskiego estymatora $\hat{p}$ w tym przypadku. Porównaj wyniki z wynikami uzyskanymi po pierwszych 20 rzutach.

* Korzystając ze wzoru na wariancję rozkładu Beta wyznacz i porównaj wariancje rozkładów a priori, a\ posteriori po 20 rzutach i a posteriori po 40 rzutach.

## Rozwiązanie

tu umieść swoje rozwiązanie

```{r}
# Parametry a priori
p_prior_mean <- 0.6
strength     <- 10
alpha_prior  <- p_prior_mean * strength
beta_prior   <- (1 - p_prior_mean) * strength

# Rozkład a priori
curve(dbeta(x, alpha_prior, beta_prior),
      from = 0, to = 1, n = 500,
      lwd = 2, col = "red",
      xlab = "p", ylab = "gęstość",
      main = expression(paste("Rozkład a priori Beta(", alpha, ", ", beta, ")")))
grid()

# Pierwsze 20 rzutów
x20 <- c(1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,0,1,1,1,1)
s20 <- sum(x20)
alpha_post_20 <- alpha_prior + s20
beta_post_20  <- beta_prior + 20 - s20
p_hat_20 <- alpha_post_20 / (alpha_post_20 + beta_post_20)

# Posterior po 20 rzutach
curve(dbeta(x, alpha_post_20, beta_post_20),
      from = 0, to = 1, n = 500,
      lwd = 2, col = "green",
      xlab = "p", ylab = "gęstość",
      main = "Rozkład Beta: a priori i a posteriori po 20")
curve(dbeta(x, alpha_prior, beta_prior), add = TRUE, col = "red", lwd = 2)
legend("topright", c("a priori","a posteriori (20)"), col=c("red","green"), lwd=2)
grid()

# Kolejne 20 rzutów 
x20b <- c(1,0,1,1,1,1,0,1,1,1,
          0,1,1,0,1,1,1,0,1,1)

# Łącznie 40 rzutów
x40b <- c(1,0,1,1,1,1,0,1,1,1,
          0,1,1,0,1,1,1,0,1,1,
          1,0,1,1,0,1,1,1,0,1,
          1,1,0,1,1,1,1,0,1,1)

s40 <- sum(x40b)
alpha_post_40 <- alpha_prior + s40
beta_post_40  <- beta_prior + 40 - s40
p_hat_40 <- alpha_post_40 / (alpha_post_40 + beta_post_40)

# Posterior po 40 rzutach
curve(dbeta(x, alpha_post_40, beta_post_40),
      from = 0, to = 1, n = 500,
      lwd = 2, col = "blue",
      xlab = "p", ylab = "gęstość",
      main = "Rozkład Beta: a priori, a posteriori po 20, po 40")
curve(dbeta(x, alpha_post_20, beta_post_20), add = TRUE, col = "green", lwd = 2)
curve(dbeta(x, alpha_prior, beta_prior),    add = TRUE, col = "red",   lwd = 2)
legend("topright", c("a priori","a post. 20","a post. 40"),
       col=c("red","green","blue"), lwd=2)
grid()

# Wariancje
beta_var <- function(a,b) a*b / ((a+b)^2 * (a+b+1))
var_prior  <- beta_var(alpha_prior,  beta_prior)
var_post20 <- beta_var(alpha_post_20, beta_post_20)
var_post40 <- beta_var(alpha_post_40, beta_post_40)
```
Wyniki pierwszych 20 rzutów: `r paste(x20, collapse=", ")`  
Wyniki kolejnych 20 rzutów: `r paste(x20b, collapse=", ")`  
Łącznie 40 rzutów: `r paste(x40b, collapse=", ")`


***

# Zadanie 4 (1,5 pkt.)

## Treść zadania

Plik fotony.txt zawiera odstępy między chwilami rejestracji kolejnych fotonów promieniowania gamma wykonywanymi za pomocą teleskopu kosmicznego Comptona (CGRO) w roku 1991.

* Wczytaj dane za pomocą komendy scan('fotony.txt')

* Metodą momentów oraz metodą największej wiarygodności wyznacz estymaty parametrów rozkładu gamma odpowiadające zarejestrowanym danym. Porównaj wyniki uzyskane dla obu metod.

* Narysuj na jednym wykresie histogram odstępów oraz funkcje gęstości rozkładu gamma o parametrach wyestymowanych za pomocą obu metod. 

* Metodą bootstrapu parametrycznego wyznacz dla obu metod (momentów oraz największej wiarygodności) odchylenia standardowe estymatorów parametrów rozkładu gamma ($\alpha$ i $\beta$) oraz ich przedziały ufności na poziomie ufności 95%. Porównaj wyniki uzyskane dla obu metod.

## Rozwiązanie

tu umieść swoje rozwiązanie

```{r}
# Wczytanie danych
fotony <- scan("fotony.txt")

# Estymacja metodą momentów
m1 <- mean(fotony); m2 <- mean(fotony^2)
alpha_mom <- m1^2 / (m2 - m1^2)
beta_mom  <- (m2 - m1^2) / m1

# Estymacja MLE (gamma: shape=k=alpha, scale=beta)
target <- log(mean(fotony)) - mean(log(fotony))
f_eq <- function(k) log(k) - digamma(k) - target
alpha_mle <- uniroot(f_eq, lower = 1e-3, upper = 100)$root
beta_mle  <- mean(fotony) / alpha_mle

# Histogram + gęstości gamma (MM vs MLE)
xmax <- as.numeric(quantile(fotony, 0.99))
nb   <- max(30, nclass.Sturges(fotony))
h <- hist(fotony, breaks = nb, plot = FALSE)
keep <- h$mids <= xmax
h$counts <- h$counts[keep]; h$mids <- h$mids[keep]
br <- h$breaks; w <- diff(br)[1]
h$breaks <- br[br <= (max(h$mids) + w)]
binw <- diff(h$breaks)
h$density <- h$counts / (sum(h$counts) * binw)

ylim_max <- max(
  h$density,
  dgamma(max(h$mids), shape = alpha_mom, scale = beta_mom),
  dgamma(max(h$mids), shape = alpha_mle, scale = beta_mle)
) * 1.15

plot(h, freq = FALSE, col = "lightblue",
     main = "Odstępy między fotonami-gamma: metoda momentów vs MLE",
     xlab = "czas", xlim = c(0, xmax), ylim = c(0, ylim_max), border = "white")
curve(dgamma(x, shape = alpha_mom, scale = beta_mom),
      add = TRUE, col = "red", lwd = 2, from = 0, to = xmax)
curve(dgamma(x, shape = alpha_mle, scale = beta_mle),
      add = TRUE, col = "green", lwd = 2, from = 0, to = xmax)
legend("topright", c("metoda momentów", "MLE"), col = c("red", "green"), lwd = 2)

# Bootstrap parametryczny dla MM i MLE
set.seed(123)
n <- length(fotony)
B <- 5000

# Funkcje estymatorów
est_mm <- function(x) {
  m1 <- mean(x); m2 <- mean(x^2)
  a <- m1^2 / (m2 - m1^2)
  b <- (m2 - m1^2) / m1
  c(a, b)
}
est_mle <- function(x) {
  tgt <- log(mean(x)) - mean(log(x))
  f <- function(k) log(k) - digamma(k) - tgt
  a <- uniroot(f, lower = 1e-3, upper = 100)$root
  b <- mean(x) / a
  c(a, b)
}

# Bootstrap dla MM (parametryczne próbki z Gamma(alpha_mom, beta_mom))
mm_boot <- replicate(B, {
  xb <- rgamma(n, shape = alpha_mom, scale = beta_mom)
  est_mm(xb)
})
alpha_mm_boot <- mm_boot[1, ]; beta_mm_boot <- mm_boot[2, ]

# Bootstrap dla MLE (parametryczne próbki z Gamma(alpha_mle, beta_mle))
mle_boot <- replicate(B, {
  xb <- rgamma(n, shape = alpha_mle, scale = beta_mle)
  est_mle(xb)
})
alpha_mle_boot <- mle_boot[1, ]; beta_mle_boot <- mle_boot[2, ]

# Odchylenia standardowe estymatorów
sd_alpha_mm  <- sd(alpha_mm_boot)
sd_beta_mm   <- sd(beta_mm_boot)
sd_alpha_mle <- sd(alpha_mle_boot)
sd_beta_mle  <- sd(beta_mle_boot)

# 95% przedziały ufności (percentylowe bootstrap)
ci_alpha_mm  <- quantile(alpha_mm_boot, c(0.025, 0.975))
ci_beta_mm   <- quantile(beta_mm_boot,  c(0.025, 0.975))
ci_alpha_mle <- quantile(alpha_mle_boot, c(0.025, 0.975))
ci_beta_mle  <- quantile(beta_mle_boot,  c(0.025, 0.975))
```
Estymaty parametrów rozkładu gamma:

- Metoda momentów: α = `r round(alpha_mom,4)`, β = `r round(beta_mom,4)`
- Metoda największej wiarygodności (MLE): α = `r round(alpha_mle,4)`, β = `r round(beta_mle,4)`

Odchylenia standardowe estymatorów (bootstrap parametryczny, B=5000):

- MM: sd(α) = `r round(sd_alpha_mm,4)`, sd(β) = `r round(sd_beta_mm,4)`
- MLE: sd(α) = `r round(sd_alpha_mle,4)`, sd(β) = `r round(sd_beta_mle,4)`

95% przedziały ufności (bootstrap percentylowy):

- MM: α ∈ [`r round(ci_alpha_mm[1],4)`, `r round(ci_alpha_mm[2],4)`], β ∈ [`r round(ci_beta_mm[1],4)`, `r round(ci_beta_mm[2],4)`]
- MLE: α ∈ [`r round(ci_alpha_mle[1],4)`, `r round(ci_alpha_mle[2],4)`], β ∈ [`r round(ci_beta_mle[1],4)`, `r round(ci_beta_mle[2],4)`]

**Porównanie:**  
Metoda momentów daje szybkie przybliżenie, ale jej estymaty są mniej stabilne (większe odchylenia standardowe).  
MLE zapewnia bardziej efektywne estymatory – przedziały ufności są węższe, a dopasowanie do histogramu lepsze.


***